Title,Author,Date,Text,URL
Open sourcing my python browser SDK that allows you use LLMs to scrape data from any site with prompts instead of scripts,rivernotch,2025-01-07,"Dendrite can be used to code AI agents / AI workflows that can:

- üëÜüèº Interact with elements
- üíø Extract structured data
- üîì Authenticate on websites
- ‚ÜïÔ∏è¬†Download/upload files
- üö´ Browse without getting blocked
‚Äì üõ†Ô∏è Self-heal if website updates

Check it out here: [https://github.com/dendrite-systems/dendrite-python-sdk](https://github.com/dendrite-systems/dendrite-python-sdk)",https://www.reddit.com/r/data/comments/1hvt0bk/open_sourcing_my_python_browser_sdk_that_allows/
"Organizing Files Across Multiple Hard Drives ‚Äì Need Advice
",mipxtube,2025-01-07,"I currently have 30-35 hard drives, and often I find myself needing a specific video or photo but can‚Äôt remember which hard drive it‚Äôs stored on.

For now, my workaround is to keep a folder on one of my drives containing screenshots of the folder structures on each hard drive. However, every time I update or move a file, I have to take a new screenshot and replace the old one, which is tedious and not very efficient.

Do you know of any software or methods that could help me better organize or search across all my hard drives? I‚Äôd greatly appreciate your suggestions!",https://www.reddit.com/r/data/comments/1hvrz39/organizing_files_across_multiple_hard_drives_need/
Best Practices for Identifying and Merging Duplicate records?,Univium,2025-01-07,"I‚Äôm working to identify and merge a large number of duplicate contact records for a client, and I need to have a bit more accuracy than I‚Äôve had in the past. (In the past, I‚Äôve had a larger team available to do a manual cleanup of potential duplicates that were identified)

We have basic details like First Name, Last Name, Company Name, Email, and Phone Number.

After cleaning up all the exact duplicates, I got us down to around 1,000 to 2,000 remaining potential duplicates.

Hard part is, some contacts switch companies, so their email address changes, and that‚Äôs relatively easy, but if someone switches companies, gets married, changes their last name, and has a different phone and email, that‚Äôs a bit more difficult. I‚Äôm also having trouble creating an algorithm to look at things like Nicknames, Name typos, jr. and sr., etc.

Sometimes there a groups of duplicates, like 3 or more matching records, which is helpful, but then I run into issues with one bad match getting included in the Duplicate Group, which messes everything up.

(I can include a GitHub link to my Python script if needed too)

But anyways, I know this is all kinda broad, but any guidance, best practices, suggestions, or stories about challenges you‚Äôve had with duplicates and how you resolved those challenges would be helpful!",https://www.reddit.com/r/data/comments/1hvqlhv/best_practices_for_identifying_and_merging/
How agentic AI revolutionizes decision-making for the C-Suite,shreyasoftweb21,2025-01-07,"Discover [how agentic AI transforms decision-making for the C-suite](https://www.softwebsolutions.com/resources/agentic-ai-for-the-c-suite.html) by acting as a trusted advisor. Learn about how AI‚Äôs agentic properties enable the company‚Äôs functional, emotional, and social jobs through the Jobs to Be Done (JTBD) framework. It allows executives to focus on what matters the most. ",https://www.reddit.com/r/data/comments/1hvo8nn/how_agentic_ai_revolutionizes_decisionmaking_for/
DEBATE : Grad in DATA SCIENCE or MBA?,Tejas1305,2025-01-07,"I personally think MBA is better as it allows for more opportunity in the future but as I have studied data science I understand how one opinion should never be considered accurate data

So let's get your input",https://www.reddit.com/r/data/comments/1hvk0rq/debate_grad_in_data_science_or_mba/
Data script step by step,Nadnadou,2025-01-07,"Hello World !

I‚Äôm looking for a simple way to visualize the transformations I apply to my data in a Python script.

Ideally, I‚Äôd like to see step-by-step changes (e.g., before/after each operation).
Any tools or libraries you‚Äôd recommend ?
",https://www.reddit.com/r/data/comments/1hvfd8g/data_script_step_by_step/
Data analysis or data science in healthcare?,0alexmyz0,2025-01-05,"Hello! I am writing the following hoping to find some advice or support regarding the topic mentioned in the title. I am a general physician with 3 years of experience, I live in Tijuana, Mexico, but I have thought that it might not be entirely my thing and I would like to dedicate myself to something else in which I can continue using that medical knowledge. I took a data science course and learned about ML, Deep learning, Python, and even data visualization. But now I don't know how to start; I looked for some projects on Kaggle, but there isn't much focused on health (or maybe I'm not good at searching). If there is any data analyst/scientist who can give me some advice, I would greatly appreciate it. I would be willing to dedicate 20-30 hours per week without pay to a company in order to gain experience, since currently my work as a doctor does not take up much of my time.",https://www.reddit.com/r/data/comments/1hul5kk/data_analysis_or_data_science_in_healthcare/
Entry Level Job Leads,XxDaUnKn0WnxX,2025-01-04,"Hi everyone! I am new to this subreddit but I wanted to some help on searching for Entry Level Data Analyst jobs. I'm a Comp Sci graduate, with a minor in Mathematics, looking to break out in the world of Data. I have very little Data experience (only worked as a researcher for a month or two and did some analysis at my current position). 

I have applied to about 100 places, but LinkedIn and Indeed do not show me positions matching my criteria (remote if in a different state, or 10-20 miles from where I live. I'm about 20 minutes from New York, NY. Any help would be greatly appreciated!",https://www.reddit.com/r/data/comments/1ht94dx/entry_level_job_leads/
Asphalt market,nkj12,2025-01-03,Completely new to finding data. Struggling to find credible data related to the segmentation of the asphalt market. Mainly segmenting it on commercial public residential other or roads waterproofing recreation other. Please replay asap im on a time crunch would appreciate any help,https://www.reddit.com/r/data/comments/1hsw734/asphalt_market/
Help for data sorting/clustering ,late-nighter,2025-01-03,"I need help with a sorting problem. I have a 90*100 image. Every pixel contains information of up to 3 gaussians, but sometimes there are less gaussians in one pixel. They represent the best fit of an emission line that is made up of multiple components. Each gaussian corresponds to a kinematic component in the emission line. I now have to sort these gaussian components, so the components are consistent across the whole image. Simply sorting by width and mean is not sufficient, as single cuts are not enough for the complex data. How can I sort my data well?",https://www.reddit.com/r/data/comments/1hsuemn/help_for_data_sortingclustering/
Data Gathering from Path Constrained Mobile Sensors Using Data MULE,Dinesh Dash,2016-12-13,"In Wireless Sensor Network (WSN) sensor nodes are deployed to sense useful data from environment. Sensors are energy-constrained devices. To prolong the sensor network lifetime, now a days mobile robots (sometimes refer as data sink, data mules, or data collectors) are used for collecting the sensed data from the sensors. In this environment sensor nodes directly transfer their sensed data to the data mules. Sensed data are sometime time sensitive; therefore, the data should be collected within a predefined period. Hence, depending on the speed of the data mules the trajectory lengths of the data mules have upper limits. In this paper an approximation algorithm is proposed for collecting data from the mobile sensors using mobile data collectors",http://arxiv.org/abs/1612.04053v1
A Survey on Sampling and Profiling over Big Data (Technical Report),"Zhicheng Liu, Aoqian Zhang",2020-05-08,"Due to the development of internet technology and computer science, data is exploding at an exponential rate. Big data brings us new opportunities and challenges. On the one hand, we can analyze and mine big data to discover hidden information and get more potential value. On the other hand, the 5V characteristic of big data, especially Volume which means large amount of data, brings challenges to storage and processing. For some traditional data mining algorithms, machine learning algorithms and data profiling tasks, it is very difficult to handle such a large amount of data. The large amount of data is highly demanding hardware resources and time consuming. Sampling methods can effectively reduce the amount of data and help speed up data processing. Hence, sampling technology has been widely studied and used in big data context, e.g., methods for determining sample size, combining sampling with big data processing frameworks. Data profiling is the activity that finds metadata of data set and has many use cases, e.g., performing data profiling tasks on relational data, graph data, and time series data for anomaly detection and data repair. However, data profiling is computationally expensive, especially for large data sets. Therefore, this paper focuses on researching sampling and profiling in big data context and investigates the application of sampling in different categories of data profiling tasks. From the experimental results of these studies, the results got from the sampled data are close to or even exceed the results of the full amount of data. Therefore, sampling technology plays an important role in the era of big data, and we also have reason to believe that sampling technology will become an indispensable step in big data processing in the future.",http://arxiv.org/abs/2005.05079v1
Data Science: A Comprehensive Overview,Longbing Cao,2020-07-01,"The twenty-first century has ushered in the age of big data and data economy, in which data DNA, which carries important knowledge, insights and potential, has become an intrinsic constituent of all data-based organisms. An appropriate understanding of data DNA and its organisms relies on the new field of data science and its keystone, analytics. Although it is widely debated whether big data is only hype and buzz, and data science is still in a very early phase, significant challenges and opportunities are emerging or have been inspired by the research, innovation, business, profession, and education of data science. This paper provides a comprehensive survey and tutorial of the fundamental aspects of data science: the evolution from data analysis to data science, the data science concepts, a big picture of the era of data science, the major challenges and directions in data innovation, the nature of data analytics, new industrialization and service opportunities in the data economy, the profession and competency of data education, and the future of data science. This article is the first in the field to draw a comprehensive big picture, in addition to offering rich observations, lessons and thinking about data science and analytics.",http://arxiv.org/abs/2007.03606v1
BDGS: A Scalable Big Data Generator Suite in Big Data Benchmarking,"Zijian Ming, Chunjie Luo, Wanling Gao, Rui Han, Qiang Yang, Lei Wang, Jianfeng Zhan",2014-01-22,"Data generation is a key issue in big data benchmarking that aims to generate application-specific data sets to meet the 4V requirements of big data. Specifically, big data generators need to generate scalable data (Volume) of different types (Variety) under controllable generation rates (Velocity) while keeping the important characteristics of raw data (Veracity). This gives rise to various new challenges about how we design generators efficiently and successfully. To date, most existing techniques can only generate limited types of data and support specific big data systems such as Hadoop. Hence we develop a tool, called Big Data Generator Suite (BDGS), to efficiently generate scalable big data while employing data models derived from real data to preserve data veracity. The effectiveness of BDGS is demonstrated by developing six data generators covering three representative data types (structured, semi-structured and unstructured) and three data sources (text, graph, and table data).",http://arxiv.org/abs/1401.5465v3
Modern Data Formats for Big Bioinformatics Data Analytics,"Shahzad Ahmed, M. Usman Ali, Javed Ferzund, Muhammad Atif Sarwar, Abbas Rehman, Atif Mehmood",2017-05-05,"Next Generation Sequencing (NGS) technology has resulted in massive amounts of proteomics and genomics data. This data is of no use if it is not properly analyzed. ETL (Extraction, Transformation, Loading) is an important step in designing data analytics applications. ETL requires proper understanding of features of data. Data format plays a key role in understanding of data, representation of data, space required to store data, data I/O during processing of data, intermediate results of processing, in-memory analysis of data and overall time required to process data. Different data mining and machine learning algorithms require input data in specific types and formats. This paper explores the data formats used by different tools and algorithms and also presents modern data formats that are used on Big Data Platform. It will help researchers and developers in choosing appropriate data format to be used for a particular tool or algorithm.",http://arxiv.org/abs/1707.05364v1
A Forecasting-Based DLP Approach for Data Security,"Kishu Gupta, Ashwani Kush",2023-12-21,"Sensitive data leakage is the major growing problem being faced by enterprises in this technical era. Data leakage causes severe threats for organization of data safety which badly affects the reputation of organizations. Data leakage is the flow of sensitive data/information from any data holder to an unauthorized destination. Data leak prevention (DLP) is set of techniques that try to alleviate the threats which may hinder data security. DLP unveils guilty user responsible for data leakage and ensures that user without appropriate permission cannot access sensitive data and also provides protection to sensitive data if sensitive data is shared accidentally. In this paper, data leakage prevention (DLP) model is used to restrict/grant data access permission to user, based on the forecast of their access to data. This study provides a DLP solution using data statistical analysis to forecast the data access possibilities of any user in future based on the access to data in the past. The proposed approach makes use of renowned simple piecewise linear function for learning/training to model. The results show that the proposed DLP approach with high level of precision can correctly classify between users even in cases of extreme data access.",http://arxiv.org/abs/2312.13704v1
A Random Sample Partition Data Model for Big Data Analysis,"Salman Salloum, Yulin He, Joshua Zhexue Huang, Xiaoliang Zhang, Tamer Z. Emara, Chenghao Wei, Heping He",2017-12-12,"Big data sets must be carefully partitioned into statistically similar data subsets that can be used as representative samples for big data analysis tasks. In this paper, we propose the random sample partition (RSP) data model to represent a big data set as a set of non-overlapping data subsets, called RSP data blocks, where each RSP data block has a probability distribution similar to the whole big data set. Under this data model, efficient block level sampling is used to randomly select RSP data blocks, replacing expensive record level sampling to select sample data from a big distributed data set on a computing cluster. We show how RSP data blocks can be employed to estimate statistics of a big data set and build models which are equivalent to those built from the whole big data set. In this approach, analysis of a big data set becomes analysis of few RSP data blocks which have been generated in advance on the computing cluster. Therefore, the new method for data analysis based on RSP data blocks is scalable to big data.",http://arxiv.org/abs/1712.04146v2
"Data Lakes, Clouds and Commons: A Review of Platforms for Analyzing and   Sharing Genomic Data",Robert L. Grossman,2018-09-05,"Data commons collate data with cloud computing infrastructure and commonly used software services, tools and applications to create biomedical resources for the large-scale management, analysis, harmonization, and sharing of biomedical data. Over the past few years, data commons have been used to analyze, harmonize and share large scale genomics datasets. Data ecosystems can be built by interoperating multiple data commons. It can be quite labor intensive to curate, import and analyze the data in a data commons. Data lakes provide an alternative to data commons and simply provide access to data, with the data curation and analysis deferred until later and delegated to those that access the data. We review software platforms for managing, analyzing and sharing genomic data, with an emphasis on data commons, but also covering data ecosystems and data lakes.",http://arxiv.org/abs/1809.01699v2
Microservices based Linked Data Quality Model for Buildings Energy   Management Services,"Muhammad Aslam Jarwar, Sajjad Ali, Ilyoung Chong",2019-10-11,"During the production, distribution, and consumption of energy, a large quantity of data is generated. For efficiently using of energy resources other supplementary data such as building information, weather, and environmental data etc. are also collected and used. All these energy data and relevant data is published as linked data in order to enhance the reusability of data and maximization of energy management services capability. However, the quality of this linked data is questionable because of wear and tears of sensors, unreliable communication channels, and highly diversification of data sources. The provision of high-quality energy management services requires high quality linked data, which reduces billing cost and improve the quality of the living environment. Assessment and improvement methodologies for the quality of data along with linked data needs to process very diverse data from highly diverse data sources. Microservices based data-driven architecture has great significance to processes highly diverse linked data with modularity, scalability, and reliability. This paper proposed microservices based architecture along with domain data and metadata ontologies to enhance and assess energy-related linked data quality.",http://arxiv.org/abs/1910.06115v1
Toward a view-based data cleaning architecture,"Toshiyuki Shimizu, Hiroki Omori, Masatoshi Yoshikawa",2019-10-24,"Big data analysis has become an active area of study with the growth of machine learning techniques. To properly analyze data, it is important to maintain high-quality data. Thus, research on data cleaning is also important. It is difficult to automatically detect and correct inconsistent values for data requiring expert knowledge or data created by many contributors, such as integrated data from heterogeneous data sources. An example of such data is metadata for scientific datasets, which should be confirmed by data managers while handling the data. To support the efficient cleaning of data by data managers, we propose a data cleaning architecture in which data managers interactively browse and correct portions of data through views. In this paper, we explain our view-based data cleaning architecture and discuss some remaining issues.",http://arxiv.org/abs/1910.11040v1
